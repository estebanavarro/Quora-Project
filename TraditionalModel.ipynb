{"cells":[{"metadata":{"trusted":true,"_uuid":"ba730a6b14b90b3e5e759624b9a2550cb71d73ac"},"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\npd.set_option('max_colwidth',240)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b12c57a8a42b558bdb0dae30ed420e8f55eee174"},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))\ntrain=pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76702167d6d3a8df80ef58b0ca26c080735ebf03"},"cell_type":"code","source":"def build_vocab(sentences, verbose =  True):\n    vocab = {}\n    for sentence in tqdm(sentences, disable = (not verbose)):\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea2ca20114cb122f98318124fd83c8511b394efc"},"cell_type":"code","source":"sentences = train[\"question_text\"].progress_apply(lambda x: x.split()).values\nvocab = build_vocab(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35cf7443b4b8193da811758b41dc2974ac0e4055"},"cell_type":"code","source":"def clean_text(x):\n\n    x = str(x)\n    for punct in \"/-\":\n        x = x.replace(punct, ' ')\n    for punct in '\"“”':\n        x = x.replace(punct, ' _quote_ ')\n    for punct in '?!.,\\'#$&>()*+-/:;<=@[\\\\]^_`{|}~' + '’':\n        x = x.replace(punct, '')\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fd0fecdfb7b921387113fbfed193e41e04acb56"},"cell_type":"code","source":"train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_text(x))\nsentences = train[\"question_text\"].apply(lambda x: x.split())\nvocab = build_vocab(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c82894a4601875cea63e3d807c5c9793cc05f26e"},"cell_type":"code","source":"import re\n\ndef clean_numbers(x):\n\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7894711c922be10e610aa11f08eb2bfe953e921e"},"cell_type":"code","source":"train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\nsentences = train[\"question_text\"].progress_apply(lambda x: x.split())\nvocab = build_vocab(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"552363caca7131d64720994aeab9ee8dbbb5cba9"},"cell_type":"code","source":"def _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\nmispell_dict = {'colour':'color',\n                'centre':'center',\n                'didnt':'did not',\n                'doesnt':'does not',\n                'wouldnt':'would not',\n                'isnt':'is not',\n                'wouldnt':'would not',\n                'shouldnt':'should not',\n                'favourite':'favorite',\n                'travelling':'traveling',\n                'counselling':'counseling',\n                'theatre':'theater',\n                'cancelled':'canceled',\n                'labour':'labor',\n                'organisation':'organization',\n                'wwii':'world war 2',\n                'citicise':'criticize',\n                'instagram': 'social_media',\n                'whatsapp': 'social_media',\n                'snapchat': 'social_media'\n\n                }\nmispellings, mispellings_re = _get_mispell(mispell_dict)\n\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff4a2849bf88ab2ec3a4f56a16f2bbc3bd988e46"},"cell_type":"code","source":"train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\nsentences = train[\"question_text\"].progress_apply(lambda x: x.split())\nto_remove = ['a','to','of','and']\nsentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\nvocab = build_vocab(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c05b729b13f9b3aab9522a3186adcf34154536d"},"cell_type":"code","source":"from sklearn import model_selection\nX = train['question_text']; y = train['target']\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6d51971f050a7c76e98553d192593fbac7d6c68a"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nCountv = CountVectorizer(binary=True, ngram_range=(1, 3)).fit(X_train)\nCount_train_binary = Countv.transform(X_train); Count_test_binary = Countv.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f9c4bc86e85f75130205acf48a1d19659f586eea"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nCountLR = LogisticRegression().fit(Count_train_binary, y_train); predCountLR = CountLR.predict_proba(Count_test_binary)[:,1]\nfprCountLR, tprCountLR, thresholdCountLR= metrics.roc_curve(y_test, predCountLR)\nroc_aucCountLR = metrics.auc(fprCountLR, tprCountLR)\nCountLRpredictions = CountLR.predict(Count_test_binary)\nF1CountLR = metrics.f1_score(y_test, CountLRpredictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b8c158b99d7e4e63fe311690b0c9e8585e15ef1a"},"cell_type":"code","source":"import numpy as np\nfrom sklearn import metrics\npr, re, th = metrics.precision_recall_curve(y_test, predCountLR)\npr, re = pr[:-1], re[:-1]\nfs = 2*np.divide(np.multiply(pr, re), np.add(pr, re))\nf = F1CountLR","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fdab1735830d2e1a7dd7b75e174225378bc0a2ab"},"cell_type":"code","source":"opt_thr = th[np.argmax(fs)]\nopt_thr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5b689bdcaeb7d908106b3f39f4673c17bccd764c"},"cell_type":"code","source":"testdf = pd.read_csv('../input/test.csv',index_col='qid')\nXt = testdf['question_text']\nTest_binary = Countv.transform(Xt)\nPredictionP = CountLR.predict_proba(Test_binary)[:,1]\nPredictions = (PredictionP > opt_thr).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"3ba499828769f671f4f8ce098f496ec10e156ed1"},"cell_type":"code","source":"testdf['prediction']=Predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4d7e30a53b2f367a3d0bf5dd23f2a1549ec6f75c"},"cell_type":"code","source":"testdf.drop('question_text',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abf63ed34d8fb978620d49edb254555e09bf0b17"},"cell_type":"code","source":"testdf.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}